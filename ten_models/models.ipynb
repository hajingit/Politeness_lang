{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn import decomposition, ensemble, neighbors, tree, neural_network\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost\n",
    "\n",
    "import string\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "import data_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 176)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_reader.read()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05805464 -0.52113092]\n",
      " [ 0.32652215 -0.35021785]\n",
      " [-0.46058144 -1.51423159]\n",
      " [-0.39751291 -2.0050897 ]\n",
      " [ 0.7812306  -0.10708989]\n",
      " [ 1.630479    1.49625811]\n",
      " [-0.05849049 -0.81698579]\n",
      " [ 0.60994349  0.18275919]\n",
      " [-0.72237744 -1.48216038]\n",
      " [ 0.86143762  1.5444956 ]]\n"
     ]
    }
   ],
   "source": [
    "print(data[:10,-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,-2:] = np.where(data[:,-2:] > 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(data[:,:-2], data[:,-2:], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, train_x, train_y, valid_x, valid_y):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(train_x, train_y)   \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(valid_x)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y), metrics.classification_report(valid_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_glm:  0.658333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.64      0.66        61\n",
      "        1.0       0.65      0.68      0.66        59\n",
      "\n",
      "avg / total       0.66      0.66      0.66       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(linear_model.LogisticRegression(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_glm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_glm:  0.616666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.57      0.57        53\n",
      "        1.0       0.66      0.66      0.66        67\n",
      "\n",
      "avg / total       0.62      0.62      0.62       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(linear_model.LogisticRegression(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_glm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (C=0.2, kernel=linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_svm:  0.675\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.64      0.67        61\n",
      "        1.0       0.66      0.71      0.68        59\n",
      "\n",
      "avg / total       0.68      0.68      0.67       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(svm.SVC(C=0.2, kernel='linear'), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_svm:  0.608333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.55      0.55        53\n",
      "        1.0       0.65      0.66      0.65        67\n",
      "\n",
      "avg / total       0.61      0.61      0.61       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(svm.SVC(C=0.2, kernel='linear'), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(C=100, kernel=linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_svm:  0.658333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.66      0.66        61\n",
      "        1.0       0.65      0.66      0.66        59\n",
      "\n",
      "avg / total       0.66      0.66      0.66       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(svm.SVC(C=100, kernel='linear'), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_svm:  0.625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.58      0.58        53\n",
      "        1.0       0.67      0.66      0.66        67\n",
      "\n",
      "avg / total       0.63      0.62      0.63       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(svm.SVC(C=100, kernel='linear'), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_NB:  0.675\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.66      0.67        61\n",
      "        1.0       0.66      0.69      0.68        59\n",
      "\n",
      "avg / total       0.68      0.68      0.67       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(naive_bayes.GaussianNB(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_NB:  0.683333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.55      0.60        53\n",
      "        1.0       0.69      0.79      0.74        67\n",
      "\n",
      "avg / total       0.68      0.68      0.68       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(naive_bayes.GaussianNB(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_NB:  0.675\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.69      0.68        61\n",
      "        1.0       0.67      0.66      0.67        59\n",
      "\n",
      "avg / total       0.67      0.68      0.67       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_NB:  0.666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.58      0.61        53\n",
      "        1.0       0.69      0.73      0.71        67\n",
      "\n",
      "avg / total       0.66      0.67      0.66       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(naive_bayes.MultinomialNB(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_RF:  0.616666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.61      0.62        61\n",
      "        1.0       0.61      0.63      0.62        59\n",
      "\n",
      "avg / total       0.62      0.62      0.62       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(ensemble.RandomForestClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_RF: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_RF:  0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.54      0.66      0.59        53\n",
      "        1.0       0.67      0.55      0.61        67\n",
      "\n",
      "avg / total       0.61      0.60      0.60       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(ensemble.RandomForestClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_RF: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_AdaBoost:  0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.61      0.64        61\n",
      "        1.0       0.63      0.69      0.66        59\n",
      "\n",
      "avg / total       0.65      0.65      0.65       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(ensemble.AdaBoostClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_AdaBoost: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_AdaBoost:  0.641666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.59      0.62      0.61        53\n",
      "        1.0       0.69      0.66      0.67        67\n",
      "\n",
      "avg / total       0.64      0.64      0.64       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(ensemble.AdaBoostClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_AdaBoost: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_knn:  0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.74      0.68        61\n",
      "        1.0       0.67      0.56      0.61        59\n",
      "\n",
      "avg / total       0.65      0.65      0.65       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(neighbors.KNeighborsClassifier(n_neighbors=7), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_knn: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_knn:  0.533333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      0.36      0.40        53\n",
      "        1.0       0.57      0.67      0.62        67\n",
      "\n",
      "avg / total       0.52      0.53      0.52       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(neighbors.KNeighborsClassifier(n_neighbors=7), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_knn: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_XGB:  0.633333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.59      0.62        61\n",
      "        1.0       0.62      0.68      0.65        59\n",
      "\n",
      "avg / total       0.64      0.63      0.63       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(xgboost.XGBClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_XGB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_XGB:  0.641666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.58      0.59        53\n",
      "        1.0       0.68      0.69      0.68        67\n",
      "\n",
      "avg / total       0.64      0.64      0.64       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(xgboost.XGBClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_XGB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_DT:  0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.51      0.53        61\n",
      "        1.0       0.54      0.59      0.56        59\n",
      "\n",
      "avg / total       0.55      0.55      0.55       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(tree.DecisionTreeClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_DT: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_DT:  0.541666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.49      0.49        53\n",
      "        1.0       0.59      0.58      0.59        67\n",
      "\n",
      "avg / total       0.54      0.54      0.54       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(tree.DecisionTreeClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_DT: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_MLP:  0.641666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.66      0.61      0.63        61\n",
      "        1.0       0.62      0.68      0.65        59\n",
      "\n",
      "avg / total       0.64      0.64      0.64       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(neural_network.MLPClassifier(max_iter=100), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_MLP: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_MLP:  0.666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.64      0.63        53\n",
      "        1.0       0.71      0.69      0.70        67\n",
      "\n",
      "avg / total       0.67      0.67      0.67       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = train_model(neural_network.MLPClassifier(max_iter=100), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_MLP: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
