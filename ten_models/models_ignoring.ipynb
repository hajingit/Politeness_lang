{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn import decomposition, ensemble, neighbors, tree, neural_network\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost\n",
    "\n",
    "import string\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "import data_reader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 176)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_reader.read()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05805464 -0.52113092]\n",
      " [ 0.32652215 -0.35021785]\n",
      " [-0.46058144 -1.51423159]\n",
      " [-0.39751291 -2.0050897 ]\n",
      " [ 0.7812306  -0.10708989]\n",
      " [ 1.630479    1.49625811]\n",
      " [-0.05849049 -0.81698579]\n",
      " [ 0.60994349  0.18275919]\n",
      " [-0.72237744 -1.48216038]\n",
      " [ 0.86143762  1.5444956 ]]\n"
     ]
    }
   ],
   "source": [
    "print(data[:10,-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(np.abs(data[:,-2])>=0.3) & (np.abs(data[:,-1])>=0.3)]\n",
    "data[:,-2:] = np.where(data[:,-2:] > 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(data[:,:-2], data[:,-2:], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 174)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = data[:,:-2]\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, train_x, train_y, valid_x, valid_y):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(train_x, train_y)   \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(valid_x)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y), metrics.classification_report(valid_y, predictions), classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(classifier_ch, classifier_en, test_x):\n",
    "    diff = []\n",
    "    pred_ch = classifier_ch.predict(test_x)\n",
    "    pred_en = classifier_en.predict(test_x)\n",
    "    for idx in range(len(test_x)):\n",
    "        if pred_ch[idx] != pred_en[idx]:\n",
    "            diff.append(idx)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_glm:  0.702127659574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.67      0.67        21\n",
      "        1.0       0.73      0.73      0.73        26\n",
      "\n",
      "avg / total       0.70      0.70      0.70        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(linear_model.LogisticRegression(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_glm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.72 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(linear_model.LogisticRegression(), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_glm:  0.723404255319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.65      0.67        20\n",
      "        1.0       0.75      0.78      0.76        27\n",
      "\n",
      "avg / total       0.72      0.72      0.72        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(linear_model.LogisticRegression(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_glm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.71 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(linear_model.LogisticRegression(), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "32\n",
      "[0, 22, 24, 25, 28, 46, 57, 59, 71, 77, 83, 92, 99, 116, 121, 127, 131, 139, 169, 184, 186, 187, 192, 193, 199, 202, 203, 205, 211, 214, 226, 227]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (C=0.2, kernel=linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_svm:  0.723404255319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.76      0.71        21\n",
      "        1.0       0.78      0.69      0.73        26\n",
      "\n",
      "avg / total       0.73      0.72      0.72        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch= train_model(svm.SVC(C=0.2, kernel='linear'), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.72 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm.SVC(C=0.2, kernel='linear'), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_svm:  0.723404255319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.70      0.68        20\n",
      "        1.0       0.77      0.74      0.75        27\n",
      "\n",
      "avg / total       0.73      0.72      0.72        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(svm.SVC(C=0.2, kernel='linear'), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.69 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm.SVC(C=0.2, kernel='linear'), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "31\n",
      "[15, 24, 25, 26, 48, 57, 59, 62, 71, 77, 83, 85, 92, 99, 115, 116, 124, 127, 131, 139, 169, 184, 186, 190, 192, 193, 202, 214, 226, 227, 231]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(C=100, kernel=linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_svm:  0.617021276596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.71      0.63        21\n",
      "        1.0       0.70      0.54      0.61        26\n",
      "\n",
      "avg / total       0.64      0.62      0.62        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(svm.SVC(C=100, kernel='linear'), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.71 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm.SVC(C=100, kernel='linear'), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_svm:  0.702127659574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.75      0.68        20\n",
      "        1.0       0.78      0.67      0.72        27\n",
      "\n",
      "avg / total       0.72      0.70      0.70        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(svm.SVC(C=100, kernel='linear'), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_svm: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.68 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm.SVC(C=100, kernel='linear'), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "33\n",
      "[5, 12, 20, 22, 24, 25, 46, 57, 71, 83, 92, 99, 105, 112, 116, 121, 122, 127, 131, 135, 138, 139, 143, 169, 186, 187, 192, 193, 199, 211, 214, 227, 234]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_NB:  0.702127659574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.52      0.61        21\n",
      "        1.0       0.69      0.85      0.76        26\n",
      "\n",
      "avg / total       0.71      0.70      0.69        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(naive_bayes.GaussianNB(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.71 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(naive_bayes.GaussianNB(), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_NB:  0.787234042553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.50      0.67        20\n",
      "        1.0       0.73      1.00      0.84        27\n",
      "\n",
      "avg / total       0.84      0.79      0.77        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(naive_bayes.GaussianNB(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.68 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(naive_bayes.GaussianNB(), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "58\n",
      "[8, 12, 17, 22, 25, 31, 32, 33, 42, 44, 46, 47, 51, 53, 56, 61, 68, 71, 75, 76, 77, 78, 80, 82, 84, 85, 88, 92, 99, 101, 104, 105, 108, 109, 112, 124, 125, 131, 152, 153, 162, 165, 172, 181, 184, 186, 190, 195, 202, 205, 212, 219, 221, 222, 223, 227, 228, 233]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_NB:  0.787234042553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.71      0.75        21\n",
      "        1.0       0.79      0.85      0.81        26\n",
      "\n",
      "avg / total       0.79      0.79      0.79        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(naive_bayes.MultinomialNB(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.71 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(naive_bayes.MultinomialNB(), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_NB:  0.787234042553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.65      0.72        20\n",
      "        1.0       0.77      0.89      0.83        27\n",
      "\n",
      "avg / total       0.79      0.79      0.78        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(naive_bayes.MultinomialNB(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_NB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.72 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(naive_bayes.MultinomialNB(), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "26\n",
      "[7, 30, 46, 48, 62, 71, 77, 80, 83, 85, 92, 115, 116, 117, 131, 137, 139, 144, 153, 157, 179, 192, 202, 203, 226, 227]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_RF:  0.808510638298\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.81      0.79        21\n",
      "        1.0       0.84      0.81      0.82        26\n",
      "\n",
      "avg / total       0.81      0.81      0.81        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(ensemble.RandomForestClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_RF: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.70 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ensemble.RandomForestClassifier(), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_RF:  0.723404255319\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.64      0.80      0.71        20\n",
      "        1.0       0.82      0.67      0.73        27\n",
      "\n",
      "avg / total       0.74      0.72      0.72        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(ensemble.RandomForestClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_RF: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.69 (+/- 0.16)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ensemble.RandomForestClassifier(), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "35\n",
      "[0, 5, 12, 22, 24, 25, 46, 57, 71, 80, 92, 99, 103, 105, 110, 111, 112, 116, 121, 131, 135, 138, 139, 143, 169, 181, 184, 186, 187, 192, 193, 199, 211, 214, 227]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_AdaBoost:  0.787234042553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.81      0.77        21\n",
      "        1.0       0.83      0.77      0.80        26\n",
      "\n",
      "avg / total       0.79      0.79      0.79        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classfier_ch = train_model(ensemble.AdaBoostClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_AdaBoost: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.69 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ensemble.AdaBoostClassifier(), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_AdaBoost:  0.787234042553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.65      0.72        20\n",
      "        1.0       0.77      0.89      0.83        27\n",
      "\n",
      "avg / total       0.79      0.79      0.78        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(ensemble.AdaBoostClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_AdaBoost: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.70 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ensemble.AdaBoostClassifier(), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "34\n",
      "[5, 22, 25, 28, 30, 36, 39, 46, 57, 59, 71, 83, 92, 99, 105, 111, 116, 117, 131, 133, 138, 139, 165, 169, 184, 186, 187, 192, 193, 195, 199, 211, 214, 227]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_knn:  0.595744680851\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.53      0.76      0.63        21\n",
      "        1.0       0.71      0.46      0.56        26\n",
      "\n",
      "avg / total       0.63      0.60      0.59        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(neighbors.KNeighborsClassifier(n_neighbors=7), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_knn: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.65 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(neighbors.KNeighborsClassifier(n_neighbors=3), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_knn:  0.63829787234\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.85      0.67        20\n",
      "        1.0       0.81      0.48      0.60        27\n",
      "\n",
      "avg / total       0.70      0.64      0.63        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(neighbors.KNeighborsClassifier(n_neighbors=7), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_knn: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.60 (+/- 0.28)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(neighbors.KNeighborsClassifier(n_neighbors=3), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "18\n",
      "[19, 46, 48, 57, 66, 73, 75, 85, 131, 137, 139, 164, 193, 206, 213, 214, 229, 233]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_XGB:  0.765957446809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.71      0.73        21\n",
      "        1.0       0.78      0.81      0.79        26\n",
      "\n",
      "avg / total       0.77      0.77      0.77        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(xgboost.XGBClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_XGB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.77 (+/- 0.16)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgboost.XGBClassifier(), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_XGB:  0.787234042553\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.80      0.76        20\n",
      "        1.0       0.84      0.78      0.81        27\n",
      "\n",
      "avg / total       0.79      0.79      0.79        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(xgboost.XGBClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_XGB: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.69 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgboost.XGBClassifier(), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "35\n",
      "[0, 3, 22, 24, 25, 28, 30, 39, 46, 57, 59, 62, 71, 77, 92, 99, 115, 116, 131, 138, 139, 141, 152, 162, 164, 169, 186, 187, 192, 193, 199, 203, 205, 214, 227]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_DT:  0.765957446809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.81      0.76        21\n",
      "        1.0       0.83      0.73      0.78        26\n",
      "\n",
      "avg / total       0.77      0.77      0.77        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(tree.DecisionTreeClassifier(), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_DT: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.66 (+/- 0.27)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree.DecisionTreeClassifier(), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_DT:  0.68085106383\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.55      0.59        20\n",
      "        1.0       0.70      0.78      0.74        27\n",
      "\n",
      "avg / total       0.68      0.68      0.68        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(tree.DecisionTreeClassifier(), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_DT: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.65 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree.DecisionTreeClassifier(), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "35\n",
      "[12, 20, 22, 24, 25, 34, 39, 46, 57, 71, 92, 99, 105, 110, 111, 112, 116, 127, 131, 133, 138, 139, 148, 169, 186, 187, 192, 193, 199, 203, 205, 211, 214, 227, 234]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_MLP:  0.659574468085\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.67      0.64        21\n",
      "        1.0       0.71      0.65      0.68        26\n",
      "\n",
      "avg / total       0.66      0.66      0.66        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_ch = train_model(neural_network.MLPClassifier(max_iter=100), train_x, train_y[:,0], valid_x, valid_y[:,0])\n",
    "print('ch_MLP: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.71 (+/- 0.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(neural_network.MLPClassifier(max_iter=100), data[:,:-2], data[:,-2], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_MLP:  0.765957446809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.75      0.73        20\n",
      "        1.0       0.81      0.78      0.79        27\n",
      "\n",
      "avg / total       0.77      0.77      0.77        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, classifier_en = train_model(neural_network.MLPClassifier(max_iter=100), train_x, train_y[:,1], valid_x, valid_y[:,1])\n",
    "print('en_MLP: ',accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold Accuracy: 0.69 (+/- 0.08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislee/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(neural_network.MLPClassifier(max_iter=100), data[:,:-2], data[:,-1], cv=10)\n",
    "print(\"K-fold Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different idx between two models: \n",
      "32\n",
      "[0, 12, 22, 25, 28, 39, 46, 57, 59, 71, 83, 92, 99, 112, 116, 121, 127, 131, 135, 138, 139, 169, 186, 187, 192, 193, 199, 205, 211, 214, 221, 227]\n"
     ]
    }
   ],
   "source": [
    "diff_list = test_models(classifier_ch, classifier_en, test_x)\n",
    "print(\"Different idx between two models: \")\n",
    "print(len(diff_list))\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
