{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import data_reader\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayerNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=174, hidden_dim=128, output_dim=1):\n",
    "        super(OneLayerNN, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = data_reader.read()\n",
    "X = arr[:, :-2]\n",
    "Y = arr[:, -2:]\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "train_test_split(X, Y, test_size=0.20, random_state=777)\n",
    "\n",
    "train_size, input_dim = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model object and loss/optimizer calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_nn = OneLayerNN(input_dim=input_dim, output_dim=1)\n",
    "one_layer_nn.parameters()\n",
    "\n",
    "optimizer = optim.SGD(one_layer_nn.parameters(), lr=0.005)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(Y_train[:,0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CH\n",
      "Training time: 0.0030014514923095703 for epoch 0, loss = 0.39887359738349915\n",
      "Training time: 0.14499926567077637 for epoch 100, loss = 0.37999552488327026\n",
      "Training time: 0.29100656509399414 for epoch 200, loss = 0.36451390385627747\n",
      "Training time: 0.42999982833862305 for epoch 300, loss = 0.3490292727947235\n",
      "Training time: 0.5739998817443848 for epoch 400, loss = 0.33325034379959106\n",
      "Training time: 0.7170000076293945 for epoch 500, loss = 0.317617803812027\n",
      "Training time: 0.8610000610351562 for epoch 600, loss = 0.30242782831192017\n",
      "Training time: 0.9999985694885254 for epoch 700, loss = 0.2880434989929199\n",
      "Training time: 1.1409986019134521 for epoch 800, loss = 0.2747819125652313\n",
      "Training time: 1.283998966217041 for epoch 900, loss = 0.2627441883087158\n"
     ]
    }
   ],
   "source": [
    "print(\"Training CH\")\n",
    "\n",
    "label_index = 0\n",
    "\n",
    "one_layer_nn.train()\n",
    "start_train = time.time()\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    inputs = torch.tensor(X_train).float()\n",
    "    golds  = torch.tensor(Y_train[:,0]).float().unsqueeze(1)\n",
    "    preds  = one_layer_nn(inputs)\n",
    "    #print(golds.shape, preds.shape)\n",
    "    loss = criterion(preds, golds)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Training time: {} for epoch {}, loss = {}\".format(time.time() - start_train, epoch, loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3169, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "one_layer_nn.eval()\n",
    "inputs = torch.tensor(X_test).float()\n",
    "golds  = torch.tensor(Y_test[:,0]).float().unsqueeze(1)\n",
    "preds  = one_layer_nn(inputs)\n",
    "#print(golds.shape, preds.shape)\n",
    "loss = criterion(preds, golds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
